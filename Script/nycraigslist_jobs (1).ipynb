{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBOhsH5s5kkj",
    "outputId": "01d73676-5c03-4ab4-e5b3-a6b4f6df11c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\aucap\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\aucap\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3CjkSjR_FAnA"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kQQlLRE-Sld",
    "outputId": "ff7c6084-7f4d-4836-c408-fbe97dcff681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~0~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~1~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~2~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~3~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~4~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~5~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~6~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~7~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~8~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~9~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~10~0\n",
      "196363\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~11~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~12~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~13~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~14~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~15~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~16~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~17~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~18~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~19~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~20~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~21~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~22~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~23~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~24~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~25~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~26~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~27~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~28~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~29~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~30~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~31~0\n",
      "196930\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~32~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~33~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~34~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~35~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~36~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~37~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~38~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~39~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~40~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~41~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~42~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~43~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~44~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~45~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~46~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~47~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~48~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~49~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~50~0\n",
      "196283\n",
      "Number of posts found: 341\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~51~0\n",
      "196871\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~52~0\n",
      "196871\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~53~0\n",
      "196871\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~54~0\n",
      "196871\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~55~0\n",
      "196871\n",
      "Number of posts found: 342\n",
      "https://newyork.craigslist.org/search/jjj#search=1~thumb~56~0\n",
      "196871\n",
      "Number of posts found: 342\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'Host': 'newyork.craigslist.org',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:124.0) Gecko/20100101 Firefox/124.0',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cookie': 'cl_tocmode=jjj%3Apic; cl_b=4|0d789d0bf0f7b02eee1318429c3e52e7ab3db2af|1712113328cENrg',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'none',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['Post ID','Data Latitude', 'Data Longitude', 'Datetime',\n",
    "                           'Compensation', 'Employment Type', 'Job Title',\n",
    "                           'Title', 'Link', 'Price', 'Location'])\n",
    "\n",
    "for i in range(0, 57):  # This will iterate i from 1 to 10\n",
    "    url = f'https://newyork.craigslist.org/search/jjj#search=1~thumb~{i}~0'\n",
    "    print(url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(len(response.text))\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    posts = html_soup.find_all('li', class_='cl-static-search-result')\n",
    "\n",
    "    print(f'Number of posts found: {len(posts)}')\n",
    "    for post in posts:\n",
    "        # Extract the title from the 'title' attribute of the <li> tag\n",
    "        title = post['title']\n",
    "\n",
    "        # Extract the href attribute from the <a> tag\n",
    "        href = post.a['href']\n",
    "        post_id = href.split('/')[-1].split('.html')[0]\n",
    "        # Fetch the content of the href URL\n",
    "        response = requests.get(href)\n",
    "        html_content = response.text\n",
    "\n",
    "        # Parse the fetched HTML content\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract data-latitude and data-longitude from the <div id=\"map\"> element\n",
    "        map_div = soup.find('div', id='map')\n",
    "        data_latitude = map_div['data-latitude'] if map_div and 'data-latitude' in map_div.attrs else 'N/A'\n",
    "        data_longitude = map_div['data-longitude'] if map_div and 'data-longitude' in map_div.attrs else 'N/A'\n",
    "\n",
    "        # Extract datetime from the <time class=\"date timeago\"> element\n",
    "        time_tag = soup.find('time', class_='date timeago')\n",
    "        datetime = time_tag['datetime'] if time_tag and 'datetime' in time_tag.attrs else 'N/A'\n",
    "\n",
    "        attrgroup = soup.find('div', class_='attrgroup')\n",
    "\n",
    "        # Initialize an empty dictionary to store the labels and values\n",
    "        attributes = {}\n",
    "\n",
    "        if attrgroup:\n",
    "          # Loop through each 'div' with class 'attr' within the 'attrgroup' div\n",
    "          for attr in attrgroup.find_all('div', class_='attr'):\n",
    "            # Extract the label and value\n",
    "            labl = attr.find('span', class_='labl').text.strip(':')\n",
    "            valu = attr.find('span', class_='valu').text.strip()\n",
    "            # Add them to the dictionary\n",
    "            attributes[labl] = valu\n",
    "\n",
    "\n",
    "        # Extract the price from the <div> tag with the class \"price\"\n",
    "        # Using `.find()` method and checking if the element exists to avoid errors\n",
    "        price_div = post.find('div', class_='price')\n",
    "        price = price_div.text.strip() if price_div else 'N/A'\n",
    "\n",
    "        # Extract the location from the <div> tag with the class \"location\"\n",
    "        # Similar check as for price to handle missing elements gracefully\n",
    "        location_div = post.find('div', class_='location')\n",
    "        location = location_div.text.strip() if location_div else 'N/A'\n",
    "\n",
    "         # Append the data to the DataFrame\n",
    "        df = df.append({'Post ID': post_id, 'Data Latitude': data_latitude,\n",
    "                        'Data Longitude': data_longitude, 'Datetime': datetime,\n",
    "                        'Compensation': attributes.get('compensation', 'N/A'),\n",
    "                        'Employment Type': attributes.get('employment type', 'N/A'),\n",
    "                        'Job Title': attributes.get('job title', 'N/A'),\n",
    "                        'Title': title, 'Link': href, 'Price': price, 'Location': location}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a7lqubSXGODL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19464, 11)\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in c:\\users\\aucap\\anaconda3\\lib\\site-packages (12.19.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-storage-blob) (4.10.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-storage-blob) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-storage-blob) (3.4.8)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.27.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aucap\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3)\n"
     ]
    }
   ],
   "source": [
    "# Microsoft Azure\n",
    "!pip install azure-storage-blob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries \n",
    "\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests \n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UploadedCraigslist_Jobs to Azure Blob Storage in container craigslist-webscrape.\n"
     ]
    }
   ],
   "source": [
    "config_file_path='config.json'\n",
    "\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "  config = json.load(config_file)\n",
    "\n",
    "\n",
    "  CONNECTION_STRING_AZURE_STORAGE = config['connectionString']\n",
    "  CONTAINER_AZURE = \"craigslist-webscrape\"\n",
    "\n",
    "blob_name = \"Craigslist_Jobs\"\n",
    "\n",
    "# Convert DataFrame to CSV\n",
    "output = StringIO()\n",
    "df.to_csv(output, index = False)\n",
    "data = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "#Create the BlobServiceClient object\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n",
    "\n",
    "#Get a Blob client using the container name and blob name\n",
    "blob_client = blob_service_client.get_blob_client(container = CONTAINER_AZURE, blob=blob_name)\n",
    "\n",
    "# Upload the CSV data\n",
    "blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "print(f\"Uploaded {blob_name} to Azure Blob Storage in container {CONTAINER_AZURE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
